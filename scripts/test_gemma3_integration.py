#!/usr/bin/env python3
"""
Gemma3 é›†æˆæµ‹è¯•è„šæœ¬
éªŒè¯ Gemma3 æ¨¡å‹é…ç½®ã€tokenizer å’Œ weight loader æ˜¯å¦æ­£ç¡®é›†æˆ
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_gemma3_config():
    """æµ‹è¯• Gemma3 æ¨¡å‹é…ç½®"""
    print("=" * 60)
    print("æµ‹è¯• 1: Gemma3 æ¨¡å‹é…ç½®")
    print("=" * 60)
    
    from openpi.models import gemma
    
    # æµ‹è¯•æ‰€æœ‰ Gemma3 å˜ä½“
    variants = ["gemma3_4b", "gemma3_4b_lora", "gemma3_300m", "gemma3_300m_lora"]
    
    for variant in variants:
        try:
            config = gemma.get_config(variant)
            print(f"âœ“ {variant:25s} - vocab_size: {config.vocab_size:,}, depth: {config.depth}, width: {config.width}")
            
            # éªŒè¯ vocab_size
            if variant.startswith("gemma3"):
                assert config.vocab_size == gemma.GEMMA3_VOCAB_SIZE, f"Expected {gemma.GEMMA3_VOCAB_SIZE}, got {config.vocab_size}"
            
            # éªŒè¯ LoRA
            if "lora" in variant:
                assert len(config.lora_configs) > 0, "LoRA configs should be present"
            else:
                assert len(config.lora_configs) == 0, "LoRA configs should not be present"
                
        except Exception as e:
            print(f"âœ— {variant:25s} - FAILED: {e}")
            return False
    
    print("âœ“ æ‰€æœ‰ Gemma3 é…ç½®æµ‹è¯•é€šè¿‡\n")
    return True


def test_gemma3_tokenizer():
    """æµ‹è¯• Gemma3 Tokenizer"""
    print("=" * 60)
    print("æµ‹è¯• 2: Gemma3 Tokenizer")
    print("=" * 60)
    
    from openpi.models import tokenizer
    import numpy as np
    
    # æ£€æŸ¥ tokenizer è·¯å¾„
    gemma3_path = Path("/root/.cache/kagglehub/models/google/gemma-3/flax/gemma3-4b-it/1")
    tokenizer_path = gemma3_path / "tokenizer.model"
    
    if not tokenizer_path.exists():
        print(f"âœ— Gemma3 tokenizer not found at {tokenizer_path}")
        print("  Please download: kagglehub.model_download('google/gemma-3/flax/gemma3-4b-it')")
        return False
    
    print(f"âœ“ Tokenizer path exists: {tokenizer_path}")
    
    try:
        # æµ‹è¯• Pi0 æ ¼å¼ (without state)
        tok = tokenizer.Gemma3Tokenizer(max_len=48)
        tokens, mask = tok.tokenize("pick up the cube")
        print(f"âœ“ Pi0 format: tokens shape={tokens.shape}, mask shape={mask.shape}")
        
        # æµ‹è¯• Pi0.5 æ ¼å¼ (with state)
        state = np.random.randn(7)
        tokens, mask = tok.tokenize("pick up the cube", state=state)
        print(f"âœ“ Pi0.5 format: tokens shape={tokens.shape}, mask shape={mask.shape}")
        
        print("âœ“ Gemma3 Tokenizer æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— Tokenizer test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_gemma3_weight_loader():
    """æµ‹è¯• Gemma3 Weight Loader"""
    print("=" * 60)
    print("æµ‹è¯• 3: Gemma3 Weight Loader")
    print("=" * 60)
    
    from openpi.training import weight_loaders
    
    # æ£€æŸ¥ checkpoint è·¯å¾„
    ckpt_path = Path("/root/.cache/kagglehub/models/google/gemma-3/flax/gemma3-4b-it/1/gemma3-4b-it")
    
    if not ckpt_path.exists():
        print(f"âœ— Gemma3 checkpoint not found at {ckpt_path}")
        print("  Please download: kagglehub.model_download('google/gemma-3/flax/gemma3-4b-it')")
        return False
    
    print(f"âœ“ Checkpoint path exists: {ckpt_path}")
    
    try:
        loader = weight_loaders.Gemma3WeightLoader(target_img_size=224)
        print(f"âœ“ Gemma3WeightLoader created successfully")
        print(f"  Target image size: {loader.target_img_size}")
        
        print("âœ“ Gemma3 Weight Loader æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— Weight loader test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_config():
    """æµ‹è¯•è®­ç»ƒé…ç½®"""
    print("=" * 60)
    print("æµ‹è¯• 4: è®­ç»ƒé…ç½®")
    print("=" * 60)
    
    from openpi.training import config
    
    # æŸ¥æ‰¾ Gemma3 LIBERO é…ç½®
    gemma3_configs = [c for c in config._CONFIGS if "gemma3_libero" in c.name]
    
    if not gemma3_configs:
        print("âœ— No Gemma3 LIBERO configs found")
        return False
    
    for cfg in gemma3_configs:
        print(f"âœ“ Found config: {cfg.name}")
        print(f"  Model: {cfg.model.paligemma_variant} + {cfg.model.action_expert_variant}")
        print(f"  Batch size: {cfg.batch_size}")
        print(f"  Train steps: {cfg.num_train_steps}")
    
    print("âœ“ è®­ç»ƒé…ç½®æµ‹è¯•é€šè¿‡\n")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("Gemma3 é›†æˆæµ‹è¯•å¥—ä»¶")
    print("=" * 60 + "\n")
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("æ¨¡å‹é…ç½®", test_gemma3_config()))
    results.append(("Tokenizer", test_gemma3_tokenizer()))
    results.append(("Weight Loader", test_gemma3_weight_loader()))
    results.append(("è®­ç»ƒé…ç½®", test_training_config()))
    
    # æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    all_passed = True
    for name, passed in results:
        status = "âœ“ PASSED" if passed else "âœ— FAILED"
        print(f"{name:20s}: {status}")
        all_passed = all_passed and passed
    
    print("=" * 60)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Gemma3 é›†æˆæˆåŠŸï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡: uv run scripts/compute_norm_stats.py --config-name pi05_gemma3_libero")
        print("  2. å¼€å§‹è®­ç»ƒ: ./train_gemma3_libero.sh")
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    sys.exit(main())
